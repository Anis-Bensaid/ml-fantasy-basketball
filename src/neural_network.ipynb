{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.21.3)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.3.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.14.0)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.17.2)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "!pip install sklearn\n",
    "!pip install pandas\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm TensorFlow sees the GPU\n",
    "from tensorflow.python.client import device_lib\n",
    "assert 'GPU' in str(device_lib.list_local_devices())\n",
    "\n",
    "# confirm Keras sees the GPU (for TensorFlow 1.X + Keras)\n",
    "tf.test.is_gpu_available(\n",
    "    cuda_only=False,\n",
    "    min_cuda_compute_capability=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.read_csv(\"data/games_7_players.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_range = range(14,392)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(14, 392)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = games.iloc[:, x_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fgm_seas_avg_p1</th>\n",
       "      <th>fgm_seas_avg_p2</th>\n",
       "      <th>fgm_seas_avg_p3</th>\n",
       "      <th>fgm_seas_avg_p4</th>\n",
       "      <th>fgm_seas_avg_p5</th>\n",
       "      <th>fgm_seas_avg_p6</th>\n",
       "      <th>fgm_seas_avg_p7</th>\n",
       "      <th>fgm_seas_avg_p8</th>\n",
       "      <th>fgm_seas_avg_p9</th>\n",
       "      <th>fgm_seas_avg_p10</th>\n",
       "      <th>...</th>\n",
       "      <th>pf_l5_p5</th>\n",
       "      <th>pf_l5_p6</th>\n",
       "      <th>pf_l5_p7</th>\n",
       "      <th>pf_l5_p8</th>\n",
       "      <th>pf_l5_p9</th>\n",
       "      <th>pf_l5_p10</th>\n",
       "      <th>pf_l5_p11</th>\n",
       "      <th>pf_l5_p12</th>\n",
       "      <th>pf_l5_p13</th>\n",
       "      <th>pf_l5_p14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.067568</td>\n",
       "      <td>4.656716</td>\n",
       "      <td>7.848101</td>\n",
       "      <td>5.548780</td>\n",
       "      <td>6.057971</td>\n",
       "      <td>5.531646</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.287671</td>\n",
       "      <td>6.444444</td>\n",
       "      <td>3.632911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.756098</td>\n",
       "      <td>4.844156</td>\n",
       "      <td>4.397260</td>\n",
       "      <td>7.308642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.435897</td>\n",
       "      <td>5.620000</td>\n",
       "      <td>1.641791</td>\n",
       "      <td>3.560976</td>\n",
       "      <td>1.612500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.088608</td>\n",
       "      <td>2.424242</td>\n",
       "      <td>6.357143</td>\n",
       "      <td>6.050633</td>\n",
       "      <td>3.701299</td>\n",
       "      <td>7.350000</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>3.901235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.575758</td>\n",
       "      <td>7.987013</td>\n",
       "      <td>6.316456</td>\n",
       "      <td>2.978261</td>\n",
       "      <td>5.493506</td>\n",
       "      <td>4.707317</td>\n",
       "      <td>5.525641</td>\n",
       "      <td>3.631579</td>\n",
       "      <td>3.074074</td>\n",
       "      <td>2.618421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.088608</td>\n",
       "      <td>2.424242</td>\n",
       "      <td>6.357143</td>\n",
       "      <td>6.050633</td>\n",
       "      <td>3.701299</td>\n",
       "      <td>7.350000</td>\n",
       "      <td>7.086420</td>\n",
       "      <td>5.408163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.531646</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12600</th>\n",
       "      <td>6.481481</td>\n",
       "      <td>10.145455</td>\n",
       "      <td>9.464286</td>\n",
       "      <td>5.765625</td>\n",
       "      <td>3.804348</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.186047</td>\n",
       "      <td>7.085714</td>\n",
       "      <td>4.777778</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12601</th>\n",
       "      <td>7.700000</td>\n",
       "      <td>6.840000</td>\n",
       "      <td>3.975000</td>\n",
       "      <td>5.137931</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.142857</td>\n",
       "      <td>3.488372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.219512</td>\n",
       "      <td>...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12602</th>\n",
       "      <td>8.164179</td>\n",
       "      <td>5.947368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.848485</td>\n",
       "      <td>2.326087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.830189</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12603</th>\n",
       "      <td>9.317073</td>\n",
       "      <td>8.762500</td>\n",
       "      <td>6.025641</td>\n",
       "      <td>5.777778</td>\n",
       "      <td>4.291667</td>\n",
       "      <td>2.684211</td>\n",
       "      <td>1.651163</td>\n",
       "      <td>2.113208</td>\n",
       "      <td>5.432099</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12604</th>\n",
       "      <td>8.914634</td>\n",
       "      <td>5.157143</td>\n",
       "      <td>7.597561</td>\n",
       "      <td>4.972973</td>\n",
       "      <td>5.898734</td>\n",
       "      <td>2.987500</td>\n",
       "      <td>5.597403</td>\n",
       "      <td>3.688312</td>\n",
       "      <td>3.171429</td>\n",
       "      <td>5.597015</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>2.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12605 rows × 378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fgm_seas_avg_p1  fgm_seas_avg_p2  fgm_seas_avg_p3  fgm_seas_avg_p4  \\\n",
       "0             6.067568         4.656716         7.848101         5.548780   \n",
       "1             9.756098         4.844156         4.397260         7.308642   \n",
       "2             0.000000         7.088608         2.424242         6.357143   \n",
       "3             4.575758         7.987013         6.316456         2.978261   \n",
       "4             7.088608         2.424242         6.357143         6.050633   \n",
       "...                ...              ...              ...              ...   \n",
       "12600         6.481481        10.145455         9.464286         5.765625   \n",
       "12601         7.700000         6.840000         3.975000         5.137931   \n",
       "12602         8.164179         5.947368         0.000000         2.848485   \n",
       "12603         9.317073         8.762500         6.025641         5.777778   \n",
       "12604         8.914634         5.157143         7.597561         4.972973   \n",
       "\n",
       "       fgm_seas_avg_p5  fgm_seas_avg_p6  fgm_seas_avg_p7  fgm_seas_avg_p8  \\\n",
       "0             6.057971         5.531646         2.000000         7.287671   \n",
       "1             0.000000         4.435897         5.620000         1.641791   \n",
       "2             6.050633         3.701299         7.350000         9.700000   \n",
       "3             5.493506         4.707317         5.525641         3.631579   \n",
       "4             3.701299         7.350000         7.086420         5.408163   \n",
       "...                ...              ...              ...              ...   \n",
       "12600         3.804348         5.333333         0.000000         3.186047   \n",
       "12601         4.600000         0.000000         6.142857         3.488372   \n",
       "12602         2.326087         0.000000         3.000000         4.830189   \n",
       "12603         4.291667         2.684211         1.651163         2.113208   \n",
       "12604         5.898734         2.987500         5.597403         3.688312   \n",
       "\n",
       "       fgm_seas_avg_p9  fgm_seas_avg_p10  ...  pf_l5_p5  pf_l5_p6  pf_l5_p7  \\\n",
       "0             6.444444          3.632911  ...       0.0       0.0       0.0   \n",
       "1             3.560976          1.612500  ...       0.0       0.0       0.0   \n",
       "2             3.901235          0.000000  ...       0.0       0.0       0.0   \n",
       "3             3.074074          2.618421  ...       0.0       0.0       0.0   \n",
       "4             0.000000          6.531646  ...       2.0       0.0       0.0   \n",
       "...                ...               ...  ...       ...       ...       ...   \n",
       "12600         7.085714          4.777778  ...       1.0       1.8       3.2   \n",
       "12601         0.000000          4.219512  ...       3.2       1.2       2.6   \n",
       "12602         0.000000          0.000000  ...       2.8       1.5       2.6   \n",
       "12603         5.432099          2.833333  ...       3.6       2.2       4.8   \n",
       "12604         3.171429          5.597015  ...       2.4       2.4       1.8   \n",
       "\n",
       "       pf_l5_p8  pf_l5_p9  pf_l5_p10  pf_l5_p11  pf_l5_p12  pf_l5_p13  \\\n",
       "0           0.0  0.000000        0.0        0.0        0.0        0.0   \n",
       "1           0.0  0.000000        0.0        0.0        0.0        0.0   \n",
       "2           0.0  0.000000        0.0        0.0        0.0        0.0   \n",
       "3           0.0  0.000000        0.0        0.0        0.0        0.0   \n",
       "4           0.0  0.000000        0.0        0.0        0.0        0.0   \n",
       "...         ...       ...        ...        ...        ...        ...   \n",
       "12600       2.2  2.800000        3.8        4.2        2.6        2.8   \n",
       "12601       2.6  1.400000        0.6        1.4        1.8        2.8   \n",
       "12602       2.4  1.333333        2.2        3.0        1.6        1.0   \n",
       "12603       1.6  2.000000        1.6        1.4        2.0        2.6   \n",
       "12604       3.4  4.600000        2.4        4.4        2.6        3.8   \n",
       "\n",
       "       pf_l5_p14  \n",
       "0            0.0  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "3            0.0  \n",
       "4            0.0  \n",
       "...          ...  \n",
       "12600        2.6  \n",
       "12601        0.8  \n",
       "12602        3.6  \n",
       "12603        2.2  \n",
       "12604        2.0  \n",
       "\n",
       "[12605 rows x 378 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = games.iloc[:, 406:420]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fp_p1</th>\n",
       "      <th>fp_p2</th>\n",
       "      <th>fp_p3</th>\n",
       "      <th>fp_p4</th>\n",
       "      <th>fp_p5</th>\n",
       "      <th>fp_p6</th>\n",
       "      <th>fp_p7</th>\n",
       "      <th>fp_p8</th>\n",
       "      <th>fp_p9</th>\n",
       "      <th>fp_p10</th>\n",
       "      <th>fp_p11</th>\n",
       "      <th>fp_p12</th>\n",
       "      <th>fp_p13</th>\n",
       "      <th>fp_p14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69.2</td>\n",
       "      <td>62.8</td>\n",
       "      <td>59.1</td>\n",
       "      <td>52.4</td>\n",
       "      <td>49.5</td>\n",
       "      <td>31.9</td>\n",
       "      <td>30.7</td>\n",
       "      <td>27.8</td>\n",
       "      <td>25.4</td>\n",
       "      <td>24.4</td>\n",
       "      <td>16.9</td>\n",
       "      <td>14.2</td>\n",
       "      <td>12.2</td>\n",
       "      <td>11.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65.5</td>\n",
       "      <td>61.7</td>\n",
       "      <td>47.7</td>\n",
       "      <td>45.2</td>\n",
       "      <td>43.7</td>\n",
       "      <td>43.5</td>\n",
       "      <td>34.3</td>\n",
       "      <td>25.5</td>\n",
       "      <td>19.1</td>\n",
       "      <td>15.5</td>\n",
       "      <td>10.2</td>\n",
       "      <td>10.1</td>\n",
       "      <td>9.9</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51.9</td>\n",
       "      <td>48.0</td>\n",
       "      <td>38.7</td>\n",
       "      <td>38.6</td>\n",
       "      <td>37.9</td>\n",
       "      <td>34.7</td>\n",
       "      <td>34.4</td>\n",
       "      <td>33.5</td>\n",
       "      <td>30.5</td>\n",
       "      <td>23.3</td>\n",
       "      <td>21.1</td>\n",
       "      <td>18.2</td>\n",
       "      <td>16.7</td>\n",
       "      <td>14.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45.2</td>\n",
       "      <td>43.3</td>\n",
       "      <td>39.4</td>\n",
       "      <td>36.5</td>\n",
       "      <td>35.9</td>\n",
       "      <td>35.9</td>\n",
       "      <td>34.3</td>\n",
       "      <td>33.5</td>\n",
       "      <td>29.8</td>\n",
       "      <td>24.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>14.1</td>\n",
       "      <td>12.4</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.9</td>\n",
       "      <td>32.8</td>\n",
       "      <td>29.8</td>\n",
       "      <td>20.0</td>\n",
       "      <td>45.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>47.7</td>\n",
       "      <td>39.8</td>\n",
       "      <td>36.4</td>\n",
       "      <td>27.8</td>\n",
       "      <td>22.8</td>\n",
       "      <td>22.7</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12600</th>\n",
       "      <td>55.1</td>\n",
       "      <td>77.4</td>\n",
       "      <td>37.7</td>\n",
       "      <td>37.1</td>\n",
       "      <td>28.9</td>\n",
       "      <td>22.4</td>\n",
       "      <td>21.9</td>\n",
       "      <td>16.2</td>\n",
       "      <td>33.5</td>\n",
       "      <td>23.3</td>\n",
       "      <td>21.3</td>\n",
       "      <td>29.1</td>\n",
       "      <td>40.4</td>\n",
       "      <td>11.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12601</th>\n",
       "      <td>29.0</td>\n",
       "      <td>81.8</td>\n",
       "      <td>28.5</td>\n",
       "      <td>38.0</td>\n",
       "      <td>47.1</td>\n",
       "      <td>26.4</td>\n",
       "      <td>32.0</td>\n",
       "      <td>19.8</td>\n",
       "      <td>30.5</td>\n",
       "      <td>21.4</td>\n",
       "      <td>31.3</td>\n",
       "      <td>27.8</td>\n",
       "      <td>30.9</td>\n",
       "      <td>32.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12602</th>\n",
       "      <td>51.1</td>\n",
       "      <td>46.1</td>\n",
       "      <td>45.4</td>\n",
       "      <td>31.2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>19.3</td>\n",
       "      <td>22.4</td>\n",
       "      <td>36.5</td>\n",
       "      <td>36.4</td>\n",
       "      <td>27.3</td>\n",
       "      <td>26.2</td>\n",
       "      <td>27.4</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12603</th>\n",
       "      <td>66.2</td>\n",
       "      <td>68.4</td>\n",
       "      <td>28.8</td>\n",
       "      <td>52.7</td>\n",
       "      <td>32.2</td>\n",
       "      <td>42.1</td>\n",
       "      <td>24.1</td>\n",
       "      <td>37.5</td>\n",
       "      <td>29.3</td>\n",
       "      <td>26.5</td>\n",
       "      <td>27.1</td>\n",
       "      <td>32.6</td>\n",
       "      <td>16.2</td>\n",
       "      <td>22.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12604</th>\n",
       "      <td>32.7</td>\n",
       "      <td>40.6</td>\n",
       "      <td>74.2</td>\n",
       "      <td>41.6</td>\n",
       "      <td>29.2</td>\n",
       "      <td>29.5</td>\n",
       "      <td>30.1</td>\n",
       "      <td>39.8</td>\n",
       "      <td>28.2</td>\n",
       "      <td>21.4</td>\n",
       "      <td>27.5</td>\n",
       "      <td>13.4</td>\n",
       "      <td>16.8</td>\n",
       "      <td>26.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12605 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fp_p1  fp_p2  fp_p3  fp_p4  fp_p5  fp_p6  fp_p7  fp_p8  fp_p9  fp_p10  \\\n",
       "0       69.2   62.8   59.1   52.4   49.5   31.9   30.7   27.8   25.4    24.4   \n",
       "1       65.5   61.7   47.7   45.2   43.7   43.5   34.3   25.5   19.1    15.5   \n",
       "2       51.9   48.0   38.7   38.6   37.9   34.7   34.4   33.5   30.5    23.3   \n",
       "3       45.2   43.3   39.4   36.5   35.9   35.9   34.3   33.5   29.8    24.0   \n",
       "4       30.9   32.8   29.8   20.0   45.3   20.6   47.7   39.8   36.4    27.8   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...     ...   \n",
       "12600   55.1   77.4   37.7   37.1   28.9   22.4   21.9   16.2   33.5    23.3   \n",
       "12601   29.0   81.8   28.5   38.0   47.1   26.4   32.0   19.8   30.5    21.4   \n",
       "12602   51.1   46.1   45.4   31.2   26.0   44.0   19.3   22.4   36.5    36.4   \n",
       "12603   66.2   68.4   28.8   52.7   32.2   42.1   24.1   37.5   29.3    26.5   \n",
       "12604   32.7   40.6   74.2   41.6   29.2   29.5   30.1   39.8   28.2    21.4   \n",
       "\n",
       "       fp_p11  fp_p12  fp_p13  fp_p14  \n",
       "0        16.9    14.2    12.2    11.6  \n",
       "1        10.2    10.1     9.9     7.9  \n",
       "2        21.1    18.2    16.7    14.2  \n",
       "3        14.5    14.1    12.4    11.2  \n",
       "4        22.8    22.7    20.1    19.5  \n",
       "...       ...     ...     ...     ...  \n",
       "12600    21.3    29.1    40.4    11.8  \n",
       "12601    31.3    27.8    30.9    32.6  \n",
       "12602    27.3    26.2    27.4    34.0  \n",
       "12603    27.1    32.6    16.2    22.3  \n",
       "12604    27.5    13.4    16.8    26.9  \n",
       "\n",
       "[12605 rows x 14 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(25, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(14, activation='relu'),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9075 samples, validate on 2269 samples\n",
      "Epoch 1/100\n",
      "9075/9075 [==============================] - 2s 195us/sample - loss: 244.0995 - mae: 11.3574 - val_loss: 179.8726 - val_mae: 10.0409\n",
      "Epoch 2/100\n",
      "9075/9075 [==============================] - 1s 91us/sample - loss: 180.1248 - mae: 9.9847 - val_loss: 177.2729 - val_mae: 9.8895\n",
      "Epoch 3/100\n",
      "9075/9075 [==============================] - 1s 91us/sample - loss: 177.7027 - mae: 9.8999 - val_loss: 174.8736 - val_mae: 9.8171\n",
      "Epoch 4/100\n",
      "9075/9075 [==============================] - 1s 90us/sample - loss: 156.4784 - mae: 9.3898 - val_loss: 112.8981 - val_mae: 8.3359\n",
      "Epoch 5/100\n",
      "9075/9075 [==============================] - 1s 90us/sample - loss: 111.9105 - mae: 8.2903 - val_loss: 111.1517 - val_mae: 8.3353\n",
      "Epoch 6/100\n",
      "9075/9075 [==============================] - 1s 90us/sample - loss: 110.9244 - mae: 8.2542 - val_loss: 110.5895 - val_mae: 8.2900\n",
      "Epoch 7/100\n",
      "9075/9075 [==============================] - 1s 91us/sample - loss: 109.9982 - mae: 8.2182 - val_loss: 110.0620 - val_mae: 8.1978\n",
      "Epoch 8/100\n",
      "9075/9075 [==============================] - 1s 91us/sample - loss: 109.3337 - mae: 8.1965 - val_loss: 110.1912 - val_mae: 8.2705\n",
      "Epoch 9/100\n",
      "9075/9075 [==============================] - 1s 96us/sample - loss: 108.9984 - mae: 8.1832 - val_loss: 109.8474 - val_mae: 8.2958\n",
      "Epoch 10/100\n",
      "9075/9075 [==============================] - 1s 95us/sample - loss: 108.6326 - mae: 8.1696 - val_loss: 111.7117 - val_mae: 8.4320\n",
      "Epoch 11/100\n",
      "9075/9075 [==============================] - 1s 95us/sample - loss: 108.2630 - mae: 8.1521 - val_loss: 108.7509 - val_mae: 8.1778\n",
      "Epoch 12/100\n",
      "9075/9075 [==============================] - 1s 95us/sample - loss: 108.0370 - mae: 8.1443 - val_loss: 109.8526 - val_mae: 8.2683\n",
      "Epoch 13/100\n",
      "9075/9075 [==============================] - 1s 97us/sample - loss: 107.8845 - mae: 8.1384 - val_loss: 108.9133 - val_mae: 8.2102\n",
      "Epoch 14/100\n",
      "9075/9075 [==============================] - 1s 96us/sample - loss: 107.5155 - mae: 8.1221 - val_loss: 109.4017 - val_mae: 8.2033\n",
      "Epoch 15/100\n",
      "9075/9075 [==============================] - 1s 94us/sample - loss: 107.3201 - mae: 8.1126 - val_loss: 108.5456 - val_mae: 8.1975\n",
      "Epoch 16/100\n",
      "9075/9075 [==============================] - 1s 91us/sample - loss: 107.0054 - mae: 8.1029 - val_loss: 109.1475 - val_mae: 8.1776\n",
      "Epoch 17/100\n",
      "9075/9075 [==============================] - 1s 94us/sample - loss: 106.9046 - mae: 8.0996 - val_loss: 108.8624 - val_mae: 8.2164\n",
      "Epoch 18/100\n",
      "9075/9075 [==============================] - 1s 98us/sample - loss: 106.9111 - mae: 8.1011 - val_loss: 109.3088 - val_mae: 8.1856\n",
      "Epoch 19/100\n",
      "9075/9075 [==============================] - 1s 97us/sample - loss: 106.6577 - mae: 8.0919 - val_loss: 110.0413 - val_mae: 8.1850\n",
      "Epoch 20/100\n",
      "9075/9075 [==============================] - 1s 93us/sample - loss: 106.4715 - mae: 8.0865 - val_loss: 108.9852 - val_mae: 8.1430\n",
      "Epoch 21/100\n",
      "9075/9075 [==============================] - 1s 96us/sample - loss: 106.2373 - mae: 8.0731 - val_loss: 111.2534 - val_mae: 8.1490\n",
      "Epoch 22/100\n",
      "9075/9075 [==============================] - 1s 97us/sample - loss: 106.0618 - mae: 8.0714 - val_loss: 108.4102 - val_mae: 8.1250\n",
      "Epoch 23/100\n",
      "9075/9075 [==============================] - 1s 97us/sample - loss: 105.9136 - mae: 8.0599 - val_loss: 109.2804 - val_mae: 8.2215\n",
      "Epoch 24/100\n",
      "9075/9075 [==============================] - 1s 98us/sample - loss: 106.0494 - mae: 8.0682 - val_loss: 108.9532 - val_mae: 8.1363\n",
      "Epoch 25/100\n",
      "9075/9075 [==============================] - 1s 98us/sample - loss: 105.4626 - mae: 8.0440 - val_loss: 108.6544 - val_mae: 8.2124\n",
      "Epoch 26/100\n",
      "9075/9075 [==============================] - 1s 99us/sample - loss: 105.4205 - mae: 8.0445 - val_loss: 108.6190 - val_mae: 8.1880\n",
      "Epoch 27/100\n",
      "9075/9075 [==============================] - 1s 97us/sample - loss: 105.2188 - mae: 8.0391 - val_loss: 109.5255 - val_mae: 8.1028\n",
      "Epoch 28/100\n",
      "9075/9075 [==============================] - 1s 95us/sample - loss: 105.1261 - mae: 8.0323 - val_loss: 108.9205 - val_mae: 8.1568\n",
      "Epoch 29/100\n",
      "9075/9075 [==============================] - 1s 93us/sample - loss: 105.1663 - mae: 8.0352 - val_loss: 107.9330 - val_mae: 8.1605\n",
      "Epoch 30/100\n",
      "9075/9075 [==============================] - 1s 92us/sample - loss: 104.9481 - mae: 8.0281 - val_loss: 108.2423 - val_mae: 8.1103\n",
      "Epoch 31/100\n",
      "9075/9075 [==============================] - 1s 91us/sample - loss: 104.6035 - mae: 8.0125 - val_loss: 108.3863 - val_mae: 8.1927\n",
      "Epoch 32/100\n",
      "9075/9075 [==============================] - 1s 93us/sample - loss: 104.7061 - mae: 8.0153 - val_loss: 108.4760 - val_mae: 8.1585\n",
      "Epoch 33/100\n",
      "9075/9075 [==============================] - 1s 90us/sample - loss: 104.4437 - mae: 8.0031 - val_loss: 107.8371 - val_mae: 8.1459\n",
      "Epoch 34/100\n",
      "9075/9075 [==============================] - 1s 93us/sample - loss: 104.4133 - mae: 8.0071 - val_loss: 108.7285 - val_mae: 8.1519\n",
      "Epoch 35/100\n",
      "9075/9075 [==============================] - 1s 96us/sample - loss: 104.3898 - mae: 8.0076 - val_loss: 108.9867 - val_mae: 8.2648\n",
      "Epoch 36/100\n",
      "9075/9075 [==============================] - 1s 97us/sample - loss: 104.3460 - mae: 8.0007 - val_loss: 108.1814 - val_mae: 8.1599\n",
      "Epoch 37/100\n",
      "9075/9075 [==============================] - 1s 97us/sample - loss: 104.0611 - mae: 7.9943 - val_loss: 108.6966 - val_mae: 8.2209\n",
      "Epoch 38/100\n",
      "9075/9075 [==============================] - 1s 98us/sample - loss: 104.1359 - mae: 7.9968 - val_loss: 109.8396 - val_mae: 8.2839\n",
      "Epoch 39/100\n",
      "9075/9075 [==============================] - 1s 96us/sample - loss: 103.8304 - mae: 7.9853 - val_loss: 108.3683 - val_mae: 8.1484\n",
      "Epoch 40/100\n",
      "9075/9075 [==============================] - 1s 98us/sample - loss: 103.6807 - mae: 7.9774 - val_loss: 109.1419 - val_mae: 8.1228\n",
      "Epoch 41/100\n",
      "9075/9075 [==============================] - 1s 96us/sample - loss: 103.7252 - mae: 7.9779 - val_loss: 108.5461 - val_mae: 8.1951\n",
      "Epoch 42/100\n",
      "9075/9075 [==============================] - 1s 98us/sample - loss: 103.6371 - mae: 7.9761 - val_loss: 108.9216 - val_mae: 8.1821\n",
      "Epoch 43/100\n",
      "9075/9075 [==============================] - 1s 97us/sample - loss: 103.8366 - mae: 7.9831 - val_loss: 108.7152 - val_mae: 8.2214\n",
      "Epoch 44/100\n",
      "9075/9075 [==============================] - 1s 93us/sample - loss: 103.8222 - mae: 7.9836 - val_loss: 109.1453 - val_mae: 8.1130\n",
      "Epoch 45/100\n",
      "9075/9075 [==============================] - 1s 97us/sample - loss: 103.5236 - mae: 7.9703 - val_loss: 108.4978 - val_mae: 8.1290\n",
      "Epoch 46/100\n",
      "9075/9075 [==============================] - 1s 96us/sample - loss: 103.6764 - mae: 7.9752 - val_loss: 108.5692 - val_mae: 8.1213\n",
      "Epoch 47/100\n",
      "9075/9075 [==============================] - 1s 99us/sample - loss: 103.1916 - mae: 7.9600 - val_loss: 108.4202 - val_mae: 8.1851\n",
      "Epoch 48/100\n",
      "9075/9075 [==============================] - 1s 97us/sample - loss: 103.1469 - mae: 7.9577 - val_loss: 111.2250 - val_mae: 8.3586\n",
      "Epoch 49/100\n",
      "9075/9075 [==============================] - 1s 100us/sample - loss: 103.1497 - mae: 7.9538 - val_loss: 108.4393 - val_mae: 8.1635\n",
      "Epoch 50/100\n",
      "9075/9075 [==============================] - 1s 96us/sample - loss: 103.1360 - mae: 7.9581 - val_loss: 108.7212 - val_mae: 8.2178\n",
      "Epoch 51/100\n",
      "9075/9075 [==============================] - 1s 95us/sample - loss: 103.0715 - mae: 7.9557 - val_loss: 108.8651 - val_mae: 8.1208\n",
      "Epoch 52/100\n",
      "9075/9075 [==============================] - 1s 98us/sample - loss: 103.0280 - mae: 7.9545 - val_loss: 109.0078 - val_mae: 8.1617\n",
      "Epoch 53/100\n",
      "9075/9075 [==============================] - 1s 96us/sample - loss: 102.9036 - mae: 7.9452 - val_loss: 108.5107 - val_mae: 8.1247\n",
      "Epoch 54/100\n",
      "9075/9075 [==============================] - 1s 97us/sample - loss: 102.6774 - mae: 7.9366 - val_loss: 109.6905 - val_mae: 8.2438\n",
      "Epoch 55/100\n",
      "9075/9075 [==============================] - 1s 95us/sample - loss: 102.7389 - mae: 7.9437 - val_loss: 108.4885 - val_mae: 8.2044\n",
      "Epoch 56/100\n",
      "9075/9075 [==============================] - 1s 93us/sample - loss: 102.5569 - mae: 7.9344 - val_loss: 108.7992 - val_mae: 8.1298\n",
      "Epoch 57/100\n",
      "9075/9075 [==============================] - 1s 93us/sample - loss: 102.2250 - mae: 7.9214 - val_loss: 108.8840 - val_mae: 8.2172\n",
      "Epoch 58/100\n",
      "9075/9075 [==============================] - 1s 97us/sample - loss: 102.4528 - mae: 7.9331 - val_loss: 110.8708 - val_mae: 8.2418\n",
      "Epoch 59/100\n",
      "9075/9075 [==============================] - 1s 97us/sample - loss: 102.5337 - mae: 7.9305 - val_loss: 109.3820 - val_mae: 8.1451\n",
      "Epoch 60/100\n",
      "9075/9075 [==============================] - 1s 96us/sample - loss: 102.3392 - mae: 7.9294 - val_loss: 108.5707 - val_mae: 8.1812\n",
      "Epoch 61/100\n",
      "9075/9075 [==============================] - 1s 98us/sample - loss: 102.2878 - mae: 7.9265 - val_loss: 109.3848 - val_mae: 8.2043\n",
      "Epoch 62/100\n",
      "9075/9075 [==============================] - 1s 96us/sample - loss: 102.0602 - mae: 7.9201 - val_loss: 109.7589 - val_mae: 8.2113\n",
      "Epoch 63/100\n",
      "9075/9075 [==============================] - 1s 98us/sample - loss: 102.3430 - mae: 7.9264 - val_loss: 108.6338 - val_mae: 8.1597\n",
      "Epoch 64/100\n",
      "9075/9075 [==============================] - 1s 96us/sample - loss: 102.0999 - mae: 7.9219 - val_loss: 108.9811 - val_mae: 8.1820\n",
      "Epoch 65/100\n",
      "9075/9075 [==============================] - 1s 97us/sample - loss: 101.9995 - mae: 7.9155 - val_loss: 108.7452 - val_mae: 8.1673\n",
      "Epoch 66/100\n",
      "9075/9075 [==============================] - 1s 100us/sample - loss: 102.0341 - mae: 7.9131 - val_loss: 109.7477 - val_mae: 8.2718\n",
      "Epoch 67/100\n",
      "9075/9075 [==============================] - 1s 95us/sample - loss: 101.9974 - mae: 7.9162 - val_loss: 109.4172 - val_mae: 8.2328\n",
      "Epoch 68/100\n",
      "9075/9075 [==============================] - 1s 97us/sample - loss: 101.7745 - mae: 7.9029 - val_loss: 109.2707 - val_mae: 8.2198\n",
      "Epoch 69/100\n",
      "9075/9075 [==============================] - 1s 92us/sample - loss: 101.7696 - mae: 7.9077 - val_loss: 109.7808 - val_mae: 8.2284\n",
      "Epoch 70/100\n",
      "9075/9075 [==============================] - 1s 95us/sample - loss: 101.8673 - mae: 7.9085 - val_loss: 110.9561 - val_mae: 8.1372\n",
      "Epoch 71/100\n",
      "9075/9075 [==============================] - 1s 96us/sample - loss: 101.7509 - mae: 7.9059 - val_loss: 109.3745 - val_mae: 8.2262\n",
      "Epoch 72/100\n",
      "9075/9075 [==============================] - 1s 99us/sample - loss: 101.6654 - mae: 7.8998 - val_loss: 108.9237 - val_mae: 8.1318\n",
      "Epoch 73/100\n",
      "9075/9075 [==============================] - 1s 97us/sample - loss: 101.6454 - mae: 7.9006 - val_loss: 109.2301 - val_mae: 8.2057\n",
      "Epoch 74/100\n",
      "9075/9075 [==============================] - 1s 95us/sample - loss: 101.4870 - mae: 7.8955 - val_loss: 109.3914 - val_mae: 8.2373\n",
      "Epoch 75/100\n",
      "9075/9075 [==============================] - 1s 97us/sample - loss: 101.5314 - mae: 7.8952 - val_loss: 109.2534 - val_mae: 8.1529\n",
      "Epoch 76/100\n",
      "9075/9075 [==============================] - 1s 98us/sample - loss: 101.2798 - mae: 7.8869 - val_loss: 110.5584 - val_mae: 8.2166\n",
      "Epoch 77/100\n",
      "9075/9075 [==============================] - 1s 94us/sample - loss: 101.4424 - mae: 7.8930 - val_loss: 108.3812 - val_mae: 8.1515\n",
      "Epoch 78/100\n",
      "9075/9075 [==============================] - 1s 94us/sample - loss: 101.2564 - mae: 7.8847 - val_loss: 109.4663 - val_mae: 8.1521\n",
      "Epoch 79/100\n",
      "9075/9075 [==============================] - 1s 93us/sample - loss: 101.4149 - mae: 7.8912 - val_loss: 109.1521 - val_mae: 8.2165\n",
      "Epoch 80/100\n",
      "9075/9075 [==============================] - 1s 95us/sample - loss: 101.1342 - mae: 7.8809 - val_loss: 109.6482 - val_mae: 8.2675\n",
      "Epoch 81/100\n",
      "9075/9075 [==============================] - 1s 96us/sample - loss: 101.1868 - mae: 7.8873 - val_loss: 109.4707 - val_mae: 8.1875\n",
      "Epoch 82/100\n",
      "9075/9075 [==============================] - 1s 96us/sample - loss: 101.0585 - mae: 7.8778 - val_loss: 109.1905 - val_mae: 8.1384\n",
      "Epoch 83/100\n",
      "9075/9075 [==============================] - 1s 99us/sample - loss: 101.0205 - mae: 7.8775 - val_loss: 111.4455 - val_mae: 8.3379\n",
      "Epoch 84/100\n",
      "9075/9075 [==============================] - 1s 96us/sample - loss: 101.1870 - mae: 7.8852 - val_loss: 109.4877 - val_mae: 8.2060\n",
      "Epoch 85/100\n",
      "9075/9075 [==============================] - 1s 97us/sample - loss: 100.9287 - mae: 7.8717 - val_loss: 110.0497 - val_mae: 8.1898\n",
      "Epoch 86/100\n",
      "9075/9075 [==============================] - 1s 98us/sample - loss: 101.0576 - mae: 7.8751 - val_loss: 109.0599 - val_mae: 8.1648\n",
      "Epoch 87/100\n",
      "9075/9075 [==============================] - 1s 96us/sample - loss: 100.8739 - mae: 7.8735 - val_loss: 109.5029 - val_mae: 8.1750\n",
      "Epoch 88/100\n",
      "9075/9075 [==============================] - 1s 97us/sample - loss: 100.8591 - mae: 7.8698 - val_loss: 108.7275 - val_mae: 8.1601\n",
      "Epoch 89/100\n",
      "9075/9075 [==============================] - 1s 94us/sample - loss: 100.8007 - mae: 7.8672 - val_loss: 112.4382 - val_mae: 8.4342\n",
      "Epoch 90/100\n",
      "9075/9075 [==============================] - 1s 94us/sample - loss: 100.6250 - mae: 7.8613 - val_loss: 109.0753 - val_mae: 8.1756\n",
      "Epoch 91/100\n",
      "9075/9075 [==============================] - 1s 97us/sample - loss: 100.8576 - mae: 7.8715 - val_loss: 109.6905 - val_mae: 8.1993\n",
      "Epoch 92/100\n",
      "9075/9075 [==============================] - 1s 93us/sample - loss: 100.6761 - mae: 7.8638 - val_loss: 110.0184 - val_mae: 8.1849\n",
      "Epoch 93/100\n",
      "9075/9075 [==============================] - 1s 99us/sample - loss: 100.9074 - mae: 7.8733 - val_loss: 109.3589 - val_mae: 8.1911\n",
      "Epoch 94/100\n",
      "9075/9075 [==============================] - 1s 95us/sample - loss: 100.6321 - mae: 7.8613 - val_loss: 109.8959 - val_mae: 8.1691\n",
      "Epoch 95/100\n",
      "9075/9075 [==============================] - 1s 98us/sample - loss: 100.5512 - mae: 7.8570 - val_loss: 109.3477 - val_mae: 8.1835\n",
      "Epoch 96/100\n",
      "9075/9075 [==============================] - 1s 97us/sample - loss: 100.4966 - mae: 7.8583 - val_loss: 110.2736 - val_mae: 8.2414\n",
      "Epoch 97/100\n",
      "9075/9075 [==============================] - 1s 97us/sample - loss: 100.5202 - mae: 7.8562 - val_loss: 109.4812 - val_mae: 8.2226\n",
      "Epoch 98/100\n",
      "9075/9075 [==============================] - 1s 98us/sample - loss: 100.4764 - mae: 7.8587 - val_loss: 109.4940 - val_mae: 8.2012\n",
      "Epoch 99/100\n",
      "9075/9075 [==============================] - 1s 98us/sample - loss: 100.3655 - mae: 7.8529 - val_loss: 110.1427 - val_mae: 8.1792\n",
      "Epoch 100/100\n",
      "9075/9075 [==============================] - 1s 96us/sample - loss: 100.4921 - mae: 7.8568 - val_loss: 110.2558 - val_mae: 8.2515\n",
      "1261/1 - 0s - loss: 111.2226 - mae: 8.2396\n",
      "[111.06459716990484, 8.239613]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['loss', 'mae']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = model.fit(X_train, y_train, validation_split=0.20, epochs=100)\n",
    "\n",
    "print(model.evaluate(X_test,  y_test, verbose=2))\n",
    "\n",
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fgm_seas_avg_p1</th>\n",
       "      <th>fgm_seas_avg_p2</th>\n",
       "      <th>fgm_seas_avg_p3</th>\n",
       "      <th>fgm_seas_avg_p4</th>\n",
       "      <th>fgm_seas_avg_p5</th>\n",
       "      <th>fgm_seas_avg_p6</th>\n",
       "      <th>fgm_seas_avg_p7</th>\n",
       "      <th>fgm_seas_avg_p8</th>\n",
       "      <th>fgm_seas_avg_p9</th>\n",
       "      <th>fgm_seas_avg_p10</th>\n",
       "      <th>...</th>\n",
       "      <th>fp_l5_p5</th>\n",
       "      <th>fp_l5_p6</th>\n",
       "      <th>fp_l5_p7</th>\n",
       "      <th>fp_l5_p8</th>\n",
       "      <th>fp_l5_p9</th>\n",
       "      <th>fp_l5_p10</th>\n",
       "      <th>fp_l5_p11</th>\n",
       "      <th>fp_l5_p12</th>\n",
       "      <th>fp_l5_p13</th>\n",
       "      <th>fp_l5_p14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12603</th>\n",
       "      <td>9.317073</td>\n",
       "      <td>8.7625</td>\n",
       "      <td>6.025641</td>\n",
       "      <td>5.777778</td>\n",
       "      <td>4.291667</td>\n",
       "      <td>2.684211</td>\n",
       "      <td>1.651163</td>\n",
       "      <td>2.113208</td>\n",
       "      <td>5.432099</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>33.48</td>\n",
       "      <td>32.8</td>\n",
       "      <td>32.54</td>\n",
       "      <td>31.92</td>\n",
       "      <td>27.36</td>\n",
       "      <td>26.54</td>\n",
       "      <td>26.54</td>\n",
       "      <td>24.72</td>\n",
       "      <td>24.44</td>\n",
       "      <td>24.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 392 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fgm_seas_avg_p1  fgm_seas_avg_p2  fgm_seas_avg_p3  fgm_seas_avg_p4  \\\n",
       "12603         9.317073           8.7625         6.025641         5.777778   \n",
       "\n",
       "       fgm_seas_avg_p5  fgm_seas_avg_p6  fgm_seas_avg_p7  fgm_seas_avg_p8  \\\n",
       "12603         4.291667         2.684211         1.651163         2.113208   \n",
       "\n",
       "       fgm_seas_avg_p9  fgm_seas_avg_p10  ...  fp_l5_p5  fp_l5_p6  fp_l5_p7  \\\n",
       "12603         5.432099          2.833333  ...     33.48      32.8     32.54   \n",
       "\n",
       "       fp_l5_p8  fp_l5_p9  fp_l5_p10  fp_l5_p11  fp_l5_p12  fp_l5_p13  \\\n",
       "12603     31.92     27.36      26.54      26.54      24.72      24.44   \n",
       "\n",
       "       fp_l5_p14  \n",
       "12603      24.34  \n",
       "\n",
       "[1 rows x 392 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games.iloc[12603:12604, 14:406]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X = games.iloc[12601:12604, 14:406].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer sequential_28 is incompatible with the layer: expected axis -1 of input shape to have value 14 but received input with shape [None, 392]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-217-2dbf9a7265be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m     return self._model_iteration(\n\u001b[1;32m    461\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         steps=steps, callbacks=callbacks, **kwargs)\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    442\u001b[0m               \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m               \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m               total_epochs=1)\n\u001b[0m\u001b[1;32m    445\u001b[0m           \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    501\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m       \u001b[0minitializer_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectIdentityDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    406\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    407\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 408\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           converted_func)\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mdistributed_function\u001b[0;34m(input_iterator)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribution_strategy_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     outputs = strategy.experimental_run_v2(\n\u001b[0;32m---> 73\u001b[0;31m         per_replica_function, args=(model, x, y, sample_weights))\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;31m# Out of PerReplica outputs reduce or pick values to return.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     all_outputs = dist_utils.unwrap_output_dict(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mexperimental_run_v2\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    758\u001b[0m       fn = autograph.tf_convert(fn, ag_ctx.control_status_ctx(),\n\u001b[1;32m    759\u001b[0m                                 convert_by_default=False)\n\u001b[0;32m--> 760\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   1785\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1787\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2130\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2131\u001b[0m         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):\n\u001b[0;32m-> 2132\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2134\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36m_predict_on_batch\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_predict_on_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(model, x)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager_learning_phase_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0;31m# are casted, not before.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m         input_spec.assert_input_compatibility(self.input_spec, inputs,\n\u001b[0;32m--> 812\u001b[0;31m                                               self.name)\n\u001b[0m\u001b[1;32m    813\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0;34m' incompatible with the layer: expected axis '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0;34m' of input shape to have value '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                 ' but received input with shape ' + str(shape))\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;31m# Check shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer sequential_28 is incompatible with the layer: expected axis -1 of input shape to have value 14 but received input with shape [None, 392]"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(model.predict(new_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fp_p1</th>\n",
       "      <th>fp_p2</th>\n",
       "      <th>fp_p3</th>\n",
       "      <th>fp_p4</th>\n",
       "      <th>fp_p5</th>\n",
       "      <th>fp_p6</th>\n",
       "      <th>fp_p7</th>\n",
       "      <th>fp_p8</th>\n",
       "      <th>fp_p9</th>\n",
       "      <th>fp_p10</th>\n",
       "      <th>fp_p11</th>\n",
       "      <th>fp_p12</th>\n",
       "      <th>fp_p13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12601</th>\n",
       "      <td>29.0</td>\n",
       "      <td>81.8</td>\n",
       "      <td>28.5</td>\n",
       "      <td>38.0</td>\n",
       "      <td>47.1</td>\n",
       "      <td>26.4</td>\n",
       "      <td>32.0</td>\n",
       "      <td>19.8</td>\n",
       "      <td>30.5</td>\n",
       "      <td>21.4</td>\n",
       "      <td>31.3</td>\n",
       "      <td>27.8</td>\n",
       "      <td>30.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12602</th>\n",
       "      <td>51.1</td>\n",
       "      <td>46.1</td>\n",
       "      <td>45.4</td>\n",
       "      <td>31.2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>19.3</td>\n",
       "      <td>22.4</td>\n",
       "      <td>36.5</td>\n",
       "      <td>36.4</td>\n",
       "      <td>27.3</td>\n",
       "      <td>26.2</td>\n",
       "      <td>27.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12603</th>\n",
       "      <td>66.2</td>\n",
       "      <td>68.4</td>\n",
       "      <td>28.8</td>\n",
       "      <td>52.7</td>\n",
       "      <td>32.2</td>\n",
       "      <td>42.1</td>\n",
       "      <td>24.1</td>\n",
       "      <td>37.5</td>\n",
       "      <td>29.3</td>\n",
       "      <td>26.5</td>\n",
       "      <td>27.1</td>\n",
       "      <td>32.6</td>\n",
       "      <td>16.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fp_p1  fp_p2  fp_p3  fp_p4  fp_p5  fp_p6  fp_p7  fp_p8  fp_p9  fp_p10  \\\n",
       "12601   29.0   81.8   28.5   38.0   47.1   26.4   32.0   19.8   30.5    21.4   \n",
       "12602   51.1   46.1   45.4   31.2   26.0   44.0   19.3   22.4   36.5    36.4   \n",
       "12603   66.2   68.4   28.8   52.7   32.2   42.1   24.1   37.5   29.3    26.5   \n",
       "\n",
       "       fp_p11  fp_p12  fp_p13  \n",
       "12601    31.3    27.8    30.9  \n",
       "12602    27.3    26.2    27.4  \n",
       "12603    27.1    32.6    16.2  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games.iloc[12601:12604, 406:419]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
